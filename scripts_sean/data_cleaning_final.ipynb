{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "from calendar import monthrange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chicago BikeShare CSV Data Cleaning and Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ride_id</th>\n",
       "      <th>started_at</th>\n",
       "      <th>start_day</th>\n",
       "      <th>start_hour</th>\n",
       "      <th>start_hour1</th>\n",
       "      <th>start_year</th>\n",
       "      <th>trip_length</th>\n",
       "      <th>start_station_name</th>\n",
       "      <th>member_casual</th>\n",
       "      <th>rideable_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>782CEA3C6968D2A6</td>\n",
       "      <td>2020-04-01 00:13:41</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>0 days 00:05:28</td>\n",
       "      <td>Kingsbury St &amp; Erie St</td>\n",
       "      <td>member</td>\n",
       "      <td>docked_bike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>07F785C9DDA3404C</td>\n",
       "      <td>2020-04-01 00:11:18</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>0 days 00:00:33</td>\n",
       "      <td>Wabash Ave &amp; 9th St</td>\n",
       "      <td>member</td>\n",
       "      <td>docked_bike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1FD159E93F7BAFA1</td>\n",
       "      <td>2020-04-01 00:02:35</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>0 days 00:08:10</td>\n",
       "      <td>Wabash Ave &amp; 16th St</td>\n",
       "      <td>member</td>\n",
       "      <td>docked_bike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>091D47E4F0FC5022</td>\n",
       "      <td>2020-04-01 00:06:44</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>0 days 00:07:17</td>\n",
       "      <td>Mies van der Rohe Way &amp; Chicago Ave</td>\n",
       "      <td>member</td>\n",
       "      <td>docked_bike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>643593E85E46A45C</td>\n",
       "      <td>2020-04-01 00:13:36</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>0 days 00:05:23</td>\n",
       "      <td>Kingsbury St &amp; Erie St</td>\n",
       "      <td>member</td>\n",
       "      <td>docked_bike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9813892</th>\n",
       "      <td>6D855DB843848DB3</td>\n",
       "      <td>2023-11-30 23:16:11</td>\n",
       "      <td>2023-11-30</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>2023</td>\n",
       "      <td>0 days 00:10:14</td>\n",
       "      <td>Canal St &amp; Adams St</td>\n",
       "      <td>member</td>\n",
       "      <td>classic_bike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9813893</th>\n",
       "      <td>447027EB102601BE</td>\n",
       "      <td>2023-11-30 23:02:56</td>\n",
       "      <td>2023-11-30</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>2023</td>\n",
       "      <td>0 days 00:21:13</td>\n",
       "      <td>Lincoln Ave &amp; Fullerton Ave</td>\n",
       "      <td>casual</td>\n",
       "      <td>electric_bike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9813894</th>\n",
       "      <td>993257B9E439A2DD</td>\n",
       "      <td>2023-11-30 23:53:54</td>\n",
       "      <td>2023-11-30</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>2023</td>\n",
       "      <td>0 days 00:09:21</td>\n",
       "      <td>Wentworth Ave &amp; Cermak Rd*</td>\n",
       "      <td>member</td>\n",
       "      <td>classic_bike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9813895</th>\n",
       "      <td>9B518D5122FD7D72</td>\n",
       "      <td>2023-11-30 23:53:34</td>\n",
       "      <td>2023-11-30</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>2023</td>\n",
       "      <td>0 days 00:09:43</td>\n",
       "      <td>Wentworth Ave &amp; Cermak Rd*</td>\n",
       "      <td>member</td>\n",
       "      <td>classic_bike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9813896</th>\n",
       "      <td>C4C352D0A2C1A450</td>\n",
       "      <td>2023-11-30 23:39:53</td>\n",
       "      <td>2023-11-30</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>2023</td>\n",
       "      <td>0 days 00:03:16</td>\n",
       "      <td>Stockton Dr &amp; Wrightwood Ave</td>\n",
       "      <td>member</td>\n",
       "      <td>electric_bike</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9813897 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ride_id          started_at   start_day  start_hour  \\\n",
       "0        782CEA3C6968D2A6 2020-04-01 00:13:41  2020-04-01           0   \n",
       "1        07F785C9DDA3404C 2020-04-01 00:11:18  2020-04-01           0   \n",
       "2        1FD159E93F7BAFA1 2020-04-01 00:02:35  2020-04-01           0   \n",
       "3        091D47E4F0FC5022 2020-04-01 00:06:44  2020-04-01           0   \n",
       "4        643593E85E46A45C 2020-04-01 00:13:36  2020-04-01           0   \n",
       "...                   ...                 ...         ...         ...   \n",
       "9813892  6D855DB843848DB3 2023-11-30 23:16:11  2023-11-30          24   \n",
       "9813893  447027EB102601BE 2023-11-30 23:02:56  2023-11-30          24   \n",
       "9813894  993257B9E439A2DD 2023-11-30 23:53:54  2023-11-30          24   \n",
       "9813895  9B518D5122FD7D72 2023-11-30 23:53:34  2023-11-30          24   \n",
       "9813896  C4C352D0A2C1A450 2023-11-30 23:39:53  2023-11-30          24   \n",
       "\n",
       "         start_hour1  start_year     trip_length  \\\n",
       "0                  0        2020 0 days 00:05:28   \n",
       "1                  0        2020 0 days 00:00:33   \n",
       "2                  0        2020 0 days 00:08:10   \n",
       "3                  0        2020 0 days 00:07:17   \n",
       "4                  0        2020 0 days 00:05:23   \n",
       "...              ...         ...             ...   \n",
       "9813892           23        2023 0 days 00:10:14   \n",
       "9813893           23        2023 0 days 00:21:13   \n",
       "9813894           23        2023 0 days 00:09:21   \n",
       "9813895           23        2023 0 days 00:09:43   \n",
       "9813896           23        2023 0 days 00:03:16   \n",
       "\n",
       "                          start_station_name member_casual  rideable_type  \n",
       "0                     Kingsbury St & Erie St        member    docked_bike  \n",
       "1                        Wabash Ave & 9th St        member    docked_bike  \n",
       "2                       Wabash Ave & 16th St        member    docked_bike  \n",
       "3        Mies van der Rohe Way & Chicago Ave        member    docked_bike  \n",
       "4                     Kingsbury St & Erie St        member    docked_bike  \n",
       "...                                      ...           ...            ...  \n",
       "9813892                  Canal St & Adams St        member   classic_bike  \n",
       "9813893          Lincoln Ave & Fullerton Ave        casual  electric_bike  \n",
       "9813894           Wentworth Ave & Cermak Rd*        member   classic_bike  \n",
       "9813895           Wentworth Ave & Cermak Rd*        member   classic_bike  \n",
       "9813896         Stockton Dr & Wrightwood Ave        member  electric_bike  \n",
       "\n",
       "[9813897 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a For loop to go through each monthly data set, clean and merge all Bike Ride Csvs\n",
    "\n",
    "# Define an Empty Merged Data frame for Bike share Data\n",
    "\n",
    "merged_rides = []\n",
    "\n",
    "# Define ranges for Years of Documents and Months of Documents\n",
    "\n",
    "years = np.arange(2020,2024,1)\n",
    "months = np.arange(1,13,1)\n",
    "\n",
    "# Function to process datetime.time objects and compute rounded hours (Lovecy)\n",
    "\n",
    "def convert_and_round(time_obj):\n",
    "    \n",
    "    # Extract hours, minutes, and seconds\n",
    "    \n",
    "    hours = time_obj.hour\n",
    "    minutes = time_obj.minute\n",
    "    seconds = time_obj.second\n",
    "\n",
    "    # Calculate total hours\n",
    "    \n",
    "    total_hours = hours + (minutes / 60) + (seconds / 3600)\n",
    "    \n",
    "    # Apply rounding logic\n",
    "    \n",
    "    rounded_hour = np.ceil(total_hours) if total_hours > 0.5 else hours\n",
    "\n",
    "    # Apply rounding logic\n",
    "    \n",
    "    return int(rounded_hour)\n",
    "\n",
    "# For loop that does through all months in a 3 year space\n",
    "\n",
    "for y in years:\n",
    "    \n",
    "    for m in months:\n",
    "        \n",
    "        # Setting File Path for Bike share Data\n",
    "        \n",
    "        filepath = Path(f\"../data/{y}{'{:02d}'.format(m)}-divvy-tripdata/{y}{'{:02d}'.format(m)}-divvy-tripdata.csv\")\n",
    "        \n",
    "        # print(filepath)\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            # read csv\n",
    "            \n",
    "            trip_data = pd.read_csv(filepath)\n",
    "            \n",
    "            # limit to chicago/ weather applicable data\n",
    "            \n",
    "            trip_data['start_lat'] = round(trip_data['start_lat'], 1)\n",
    "            trip_data['start_lng'] = round(trip_data['start_lng'], 1)\n",
    "            \n",
    "            trip_data_chicago = trip_data.loc[(trip_data['start_lat'] == 41.9) \n",
    "                                & (trip_data['start_lng'] == -87.6), :]\n",
    "            \n",
    "            \n",
    "            # remove irrelevant data columns\n",
    "            \n",
    "            trip_sorted_data = trip_data_chicago[['ride_id', 'started_at', 'ended_at', 'start_station_name', \n",
    "                                                'member_casual', 'rideable_type']].copy()\n",
    "            \n",
    "            \n",
    "            # translate started at to Start Date and Start Hour\n",
    "            \n",
    "            trip_sorted_data['started_at'] = trip_sorted_data['started_at'].astype('datetime64[s]')\n",
    "            trip_sorted_data['start_day'] = trip_sorted_data['started_at'].dt.date\n",
    "            trip_sorted_data['start_hour1'] = trip_sorted_data['started_at'].dt.hour \n",
    "            trip_sorted_data['start_time'] = trip_sorted_data['started_at'].dt.time \n",
    "            trip_sorted_data['start_year'] = trip_sorted_data['started_at'].dt.year\n",
    "            \n",
    "            # Apply the time rounding  function to the 'start_time' column (Lovecy)\n",
    "            \n",
    "            trip_sorted_data['start_hour'] = trip_sorted_data['start_time'].apply(convert_and_round)\n",
    "            \n",
    "            # Account for the irregular 24 in the start hour\n",
    "            \n",
    "            if trip_sorted_data['start_hour'] == 24.0:\n",
    "                \n",
    "                trip_sorted_data['start_hour'] = 0\n",
    "                trip_sorted_data['start_day'] += pd.Timedelta(days=1)\n",
    "            \n",
    "            # add new TRIP LENGTH column\n",
    "            \n",
    "            trip_sorted_data['started_at'] = pd.to_datetime(trip_sorted_data['started_at'])\n",
    "            trip_sorted_data['ended_at'] = pd.to_datetime(trip_sorted_data['ended_at'])\n",
    "            \n",
    "            trip_sorted_data['trip_length'] = trip_sorted_data['ended_at'] - trip_sorted_data['started_at']\n",
    "            \n",
    "            # remove bad data & remove/ reorder Columns\n",
    "            \n",
    "            trip_data_clean = trip_sorted_data.loc[trip_sorted_data['trip_length'] > \"P0DT0H0M0S\", :]\n",
    "            trip_data_clean = trip_data_clean.dropna(how = 'any')\n",
    "            \n",
    "            trip_data_clean = trip_data_clean[['ride_id', 'started_at', 'start_day', 'start_hour', 'start_hour1', 'start_year', 'trip_length', \n",
    "                                                'start_station_name', 'member_casual', 'rideable_type']].copy()\n",
    "            \n",
    "            # sort by started_at and fix index\n",
    "            \n",
    "            trip_data_clean = trip_data_clean.sort_values(['start_day', 'start_hour']).set_index('ride_id').reset_index()\n",
    "            \n",
    "            # display(trip_data_clean.count())\n",
    "            \n",
    "            merged_rides.append(trip_data_clean)\n",
    "            \n",
    "        # Skip Non-Existing files\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            \n",
    "            pass\n",
    "            \n",
    "            # check which files are skipped\n",
    "            \n",
    "            # print(f\"an Exception occured at - {y}{'{:02d}'.format(m)}\")\n",
    "\n",
    "\n",
    "\n",
    "combined_bike_df = pd.concat(merged_rides, ignore_index=True)\n",
    "\n",
    "combined_bike_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chicago Weather CSV Data Cleaning and Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Start Weather Data Data Cleaning\n",
    "\n",
    "# Setting File Path for Csv\n",
    "\n",
    "weather_filepath = Path('../data/chicago_weather_data_2020_2023_Celcius.csv')\n",
    "\n",
    "# Read Csv data\n",
    "\n",
    "weather_data = pd.read_csv(weather_filepath)\n",
    "\n",
    "# Convert Started at to DT\n",
    "\n",
    "weather_data['dt_iso'] = pd.to_datetime(weather_data['dt_iso'], format='%Y-%m-%d %H:%M:%S %z UTC', utc=True)\n",
    "\n",
    "# Convert UTC to Chicago time by designating a time zone\n",
    "\n",
    "weather_data['dt_iso_chicago'] = weather_data['dt_iso'].dt.tz_convert('America/Chicago')\n",
    "\n",
    "# translate started at into start day and start hour\n",
    "\n",
    "weather_data['start_day'] = weather_data['dt_iso_chicago'].dt.date\n",
    "weather_data['start_hour'] = weather_data['dt_iso_chicago'].dt.hour\n",
    "\n",
    "# remove irrelevant data columns and duplicated data\n",
    "\n",
    "weather_data_sorted = weather_data[['start_day', 'start_hour', 'temp', 'dew_point', 'feels_like', \n",
    "                                'temp_min', 'temp_max', 'pressure', 'humidity', 'wind_speed', 'wind_deg',\n",
    "                                'clouds_all', 'weather_id', 'weather_main', 'weather_description']].copy()\n",
    "\n",
    "weather_data_sorted = weather_data_sorted.drop_duplicates(subset=['start_day', 'start_hour'])\n",
    "\n",
    "weather_data_sorted\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge the Data Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the Datasets\n",
    "\n",
    "result = pd.merge(combined_bike_df, weather_data_sorted, on=['start_day', 'start_hour'], how='inner')\n",
    "\n",
    "# return1 = result.loc[result['start_hour'] == 1, :]\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Merged CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save file\n",
    "\n",
    "export_merged_filepath = Path('../output/merged_weather_bike_data.csv')\n",
    "\n",
    "result.to_csv(export_merged_filepath, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
